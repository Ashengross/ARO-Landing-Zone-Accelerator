---
title: Operations and BCDR for ARO
description: Learn about considerations for your operations baseline for Azure Red Hat OpenShift.
author: SriniPadala
ms.author: srpadala
ms.date: 06/10/2022
ms.topic: conceptual
ms.service: cloud-adoption-framework
ms.subservice: scenario
ms.custom: think-tank, e2e-aro
---

# Operations baseline considerations for Azure Redhat OpenShift

Kubernetes is a relatively new technology, rapidly evolving with an impressive ecosystem. As such, it can be challenging to manage it. By properly designing your Azure Red Hat OpenShift (ARO) solution with management and monitoring in mind, you can work toward operational excellence and customer success.

## Design considerations

Consider the following factors:

- Review [responsibility matrix](https://docs.microsoft.com/en-us/azure/openshift/responsibility-matrix) to understand the responsibilities of Microsoft, Red Hat, and customers for Azure Red Hat OpenShift clusters.
- Be aware of the [Azure Quotas](https://docs.microsoft.com/en-us/azure/azure-resource-manager/management/azure-subscription-service-limits#virtual-machines-limits---azure-resource-manager)/[Regional limits](https://docs.microsoft.com/en-us/azure/openshift/openshift-faq#which-azure-regions-are-supported). Ensure capacity availability to deploy the resources.
- Be aware of ways to isolate workloads logically within a cluster and physically in separate clusters.
- Be aware of ways to help Kubernetes understand the health of your workloads.
- Be aware of various [virtual machines sizes](https://docs.microsoft.com/en-us/azure/openshift/openshift-faq#what-virtual-machine-sizes-can-i-use) and the impact of using one or the other.
- Be aware of ways to monitor and log ARO. Kubernetes consists of various components and monitoring and logging should provide an insight of its health, trends as well as potential issues.
- Building on monitoring and logging there can be many events generated by Kubernetes or applications running on top. Alerts can help differentiate between log entries for historical purposes and those that require immediate action.
- Be aware of updates and upgrades that you should do. Critical patch updates are applied to clusters automatically by Azure Red Hat OpenShift Site Reliability Engineers (SRE). Customers that wish to install patch updates in advance are free to do so.
- Be aware of resource limitations of the cluster as well as individual workloads.
- Be aware of the differences between [horizontal pod autoscaler](https://docs.openshift.com/container-platform/4.10/nodes/pods/nodes-pods-autoscaling.html) and [cluster autoscaling](https://docs.openshift.com/container-platform/4.10/machine_management/applying-autoscaling.html)
- Review [support lifecycle](https://docs.microsoft.com/en-us/azure/openshift/support-lifecycle) and understand the version support policy. Azure Red Hat OpenShift supports two generally available (GA) minor versions of Red Hat OpenShift Container Platform. Support requests require the cluster to be within a supported version.
- Review cross-namespace networking to secure traffic within the cluster using [Network Policy](https://docs.openshift.com/container-platform/4.10/networking/network_policy/about-network-policy.html)


## Design recommendations

- ARO has a rich operator ecosystem and should be leveraged for performing and automating operational activities with efficiency and accuracy.
- Add health probes to your pods to monitor application health. Make sure pods contain livenessProbe, readinessProbe. Use Startup probes to determine the point at which the application has started up.
- Use VM sizes big enough to contain multiple container instances so you get the benefits of increased density, but not so big that your cluster can't handle the workload of a failing node. 
- Regulate cluster functions using [admission plug-ins](https://docs.openshift.com/container-platform/4.10/architecture/admission-plug-ins.html). They are commonly used to enforce security policy, resource limitations or configuration requirements.
- Use pod requests and limits to manage the compute resources within a cluster. Pod requests and limits inform the Kubernetes scheduler which compute resources to assign to a pod. Restrict resource consumption in a project using [Limit Ranges](https://docs.openshift.com/container-platform/4.10/nodes/clusters/nodes-cluster-limit-ranges.html)
- Optimize the CPU and memory request values and maximize the efficiency of the cluster resources using [Vertical Pod Autoscaler](https://docs.openshift.com/container-platform/4.10/nodes/pods/nodes-pods-vertical-autoscaler.html) 
- OpenShift web console contains all metrics at the node level. Establish a monitoring process using the inbuilt Prometheus or Container Insights integration.
- Establish the monitoring tooling and process
  - Prometheus comes pre-installed and configured for Azure Red Hat OpenShift 4.x clusters
  - Container Insights can be enabled by onboarding the cluster to Azure Arc enabled Kubernetes.
- Automate application delivery process through DevOps practices and CI/CD solutions like Pipelines/GitOps provided by OpenShift Container Platform
- Define ClusterAutoScaler and MachineAutoScaler to scale machines when cluster runs out of resources to support more deployments.
- Deploy machine health checks to automatically repair damaged machines in a machine pool.
- Scale pods to meet demand using [Horizontal Pod Autoscaler](https://docs.openshift.com/container-platform/4.10/nodes/pods/nodes-pods-autoscaling.html)
- Use an alerting system to provide notifications when things need direct action. Container Insights [Metric alerts](/azure/azure-monitor/containers/container-insights-metric-alerts) or in-built [Alerting UI](https://docs.openshift.com/container-platform/4.10/monitoring/managing-alerts.html)

# Business continuity and disaster recovery considerations for ARO

Your organization needs to design suitable Azure Red Hat OpenShift (ARO) platform-level capabilities to meet its specific requirements. These application services have requirements related to recovery time objective (RTO) and recovery point objective (RPO). There are multiple considerations to address for ARO disaster recovery. Your first step is to define a service-level agreement (SLA) for your infrastructure and application. Learn about the [SLA for Azure Red Hat OpenShift (ARO)]([https://azure.microsoft.com/support/legal/sla/kubernetes-service](https://azure.microsoft.com/en-us/support/legal/sla/openshift/v1_0/)). See the **SLA details** section for information about monthly uptime calculations.

## Design considerations

Consider the following factors:

- The ARO cluster should use multiple machinesets to provide the minimum level of availability for your application.
- Set pod requests and limits. Setting these limits lets Kubernetes:
  - Efficiently give CPU and memory resources to the pods.
  - Have higher container density on a node.
  - Limits can also increase reliability with reduced costs because of better use of hardware.
- Spread nodes across all the available zones for higher availability.
  - Choose a region that supports Availability Zones.
  - For complete zonal benefit, all service dependencies must also support zones. If a dependent service does not support zones, it's possible that a zone failure could cause that service to fail.
  - For higher availability beyond what Availability Zones can achieve, run multiple clusters in different paired regions. If an Azure resource supports geo-redundancy, provide the location where the redundant service will have its secondary region.
- Consistently create backups for applications and data.
  - A non-stateful service can be replicated efficiently.
  - If you need to store *state* in the cluster, back up the data frequently in the paired region.
- Cluster upgrade and maintenance.
  - Always keep your cluster up to date. Check for [cluster upgrades](https://docs.microsoft.com/en-us/azure/openshift/howto-upgrade#check-for-azure-red-hat-openshift-cluster-upgrades)
  - Be aware of the release and deprecation process.
  - Control upgrades through schedules
- Network connectivity if a failover occurs.
  - If you need to distribute traffic across regions, consider using [Azure Front Door](/azure/frontdoor/front-door-overview).
- Planned and unplanned failovers.
  - When setting up each Azure service, choose features that support disaster recovery. For example, if [Azure Container Registry](/azure/container-registry/container-registry-intro) is chosen, enable it for geo-replication. If a region goes down, you can still pull images from the replicated region.
- Maintain engineering DevOps capabilities to reach service level goals.

## Design recommendations

The following are best practices for your design:

- Azure Red Hat OpenShift clusters are provisioned with three control plane nodes and three or more worker nodes. Ensure that the cluster is created in a region that supports availability zones so that the nodes are spread across the zones.
- Do not run extra workloads on the control plane nodes. While they can be scheduled on the control plane nodes, it will cause extra resource usage and stability issues that can affect the entire cluster.
- Create Infrastructure machinesets to hold infrastructure components. Apply specific Kubernetes labels to these Machines and then update the infrastructure components to run on only those Machines.
- For high availability, deploy these nodes to different availability zones. Since you need different machine sets for each availability zone, create at least three machine sets.
- Regular upkeep of your cluster, for example, making timely updates, is crucial for reliability. Azure Red Hat OpenShift supports two generally available (GA) minor versions of Red Hat OpenShift Container Platform. It is recommended to keep the cluster on the latest OpenShift version to avoid potential upgrade issues. Also, monitoring the health of the pods through probes is recommended.
- Whenever possible, remove the service state from inside containers. Instead, use an Azure platform as a service (PaaS) that supports multiregion replication.
- Ensure pod resources. It's highly recommended that deployments specify pod resource requirements. The scheduler can then appropriately schedule the pod. Reliability depreciates significantly when pods aren't scheduled.
- Set up multiple replicas in the deployment to handle disruptions like hardware failures. For planned events like updates and upgrades, a disruption budget can ensure the required number of pod replicas exist to handle expected application load.
- Leverage [Pod Topology](https://docs.openshift.com/container-platform/4.9/nodes/scheduling/nodes-scheduler-pod-topology-spread-constraints.html) Constraints to automatically schedule pods on nodes throughout the cluster
- Your applications might use Storage for their data and should ensure availability across regions if needed
	- Using RWX storage with inbuilt [Azure Files storage class](https://docs.microsoft.com/en-us/azure/openshift/howto-create-a-storageclass)
	- Using CSI Drivers for storage provisioning
- Create Application backup and plan for restore 	
	- Include [persistent volumes](https://docs.microsoft.com/en-us/azure/openshift/howto-create-a-backup#create-a-backup-with-velero-to-include-snapshots) in the backup
- Estimate pod resource limits. Test and establish a baseline. Start with equal values for requests and limits. Then, gradually tune those values until you've established a threshold that can cause instability in the cluster. Pod limits can be specified in your deployment manifests. [Vertical Pod Autoscaler](https://docs.openshift.com/container-platform/4.10/nodes/pods/nodes-pods-vertical-autoscaler.html) optimizes the CPU and memory request values and can maximize the efficiency of cluster resources.
  The built-in features provide a solution to the complex task of handling failures and disruptions in service architecture. These configurations help to simplify both design and deployment automation. When an organization has defined a standard for the SLA, RTO, and RPO, it can use built-in services to Kubernetes and Azure to achieve its business goals.
- Consider Blue/Green or Canary strategies to deploy new releases of application
- Set [pod priority](https://docs.openshift.com/container-platform/4.10/nodes/pods/nodes-pods-priority.html)/pod disruption budgets to limit the number of pod replicas that the cluster is allowed to take down for maintenance operations thereby ensuring availability.
- Enforce resource quotas on the service namespaces. The resource quota on a namespace will ensure pod requests and limits are properly set on a deployment.
  - Setting resources quotas at the cluster level can cause problems when deploying partner services that don't have proper requests and limits.
- Store your container images in [Azure Container Registry](https://docs.microsoft.com/en-us/azure/openshift/howto-use-acr-with-aro) and [geo-replicate](https://docs.microsoft.com/en-us/azure/container-registry/container-registry-geo-replication) the registry to each ARO region.
- Use multiple regions and peering locations for [Azure ExpressRoute](/azure/expressroute/expressroute-introduction) connectivity.
  If an outage affecting an Azure region or peering provider location occurs, a redundant hybrid network architecture can help ensure uninterrupted cross-premises connectivity.
- Interconnect regions with global virtual network peering. If the clusters need to talk to each other, connecting both virtual networks to each other can be achieved through virtual network peering. This technology interconnects virtual networks to each other providing high bandwidth across Microsoft's backbone network, even across different geographic regions.
- Using split TCP-based anycast protocol, [Azure Front Door Service](https://docs.microsoft.com/en-us/azure/frontdoor/front-door-overview) promptly connects your end users to the nearest Front Door POP (Point of Presence). More features of Azure Front Door Service:
  - TLS termination
  - Custom domain
  - Web application firewall
  - URL Rewrite
  - Session affinity
  Review the needs of your application traffic to learn which solution is the most suitable.
